#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import openai
import os
import sys
from datetime import datetime
from dotenv import load_dotenv

# ì‹œìŠ¤í…œ ì¸ì½”ë”©ì„ UTF-8ë¡œ ì„¤ì •
if sys.platform.startswith('win'):
    import locale
    locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')

# í‘œì¤€ ì¶œë ¥/ì—ëŸ¬ë¥¼ UTF-8ë¡œ ì„¤ì •
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

# .env íŒŒì¼ ë¡œë”©
load_dotenv()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI Curriculum Generator API",
    description="OpenAI GPTë¥¼ í™œìš©í•œ ìŠ¤í„°ë””/í”„ë¡œì íŠ¸ ì»¤ë¦¬í˜ëŸ¼ ìƒì„± API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')

# Pydantic ëª¨ë¸ ì •ì˜
class CurriculumRequest(BaseModel):
    study_project_id: int
    study_project_name: str
    study_project_title: str
    study_project_desc: str
    study_level: int
    interest_tags: List[str]
    study_project_start: str
    study_project_end: str
    type_check: str = "study"

class CurriculumResponse(BaseModel):
    study_project_id: int
    curriculum: str
    message: str
    success: bool
    generated_at: str

class FeedbackRequest(BaseModel):
    assignment_title: str
    assignment_description: str
    submission_content: str
    submission_file_url: Optional[str] = None

class FeedbackResponse(BaseModel):
    score: int
    comment: str
    detailed_feedback: str

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {"message": "AI Curriculum Generator API", "status": "running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.post("/generate-curriculum", response_model=CurriculumResponse)
async def generate_curriculum(request: CurriculumRequest):
    """
    OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤í„°ë””/í”„ë¡œì íŠ¸ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # OpenAI API í‚¤ í™•ì¸
        if not openai.api_key:
            raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë ˆë²¨ì— ë”°ë¥¸ ì„¤ëª… ìƒì„±
        level_descriptions = {
            1: "ì´ˆê¸‰ì (ê¸°ì´ˆ ê°œë… í•™ìŠµ)",
            2: "ì¤‘ê¸‰ì (ê¸°ë³¸ ì‹¤ìŠµ ë° ì‘ìš©)",
            3: "ê³ ê¸‰ì (ì‹¬í™” í•™ìŠµ ë° í”„ë¡œì íŠ¸)"
        }
        
        level_desc = level_descriptions.get(request.study_level, "ì¤‘ê¸‰ì")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {request.study_project_name} {request.type_check}ë¥¼ ìœ„í•œ ìƒì„¸í•œ ì»¤ë¦¬í˜ëŸ¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**{request.type_check.capitalize()} ì •ë³´:**
- ì´ë¦„: {request.study_project_name}
- ì œëª©: {request.study_project_title}
- ì„¤ëª…: {request.study_project_desc}
- ìˆ˜ì¤€: {level_desc} (ë ˆë²¨ {request.study_level})
- ê´€ì‹¬ ë¶„ì•¼: {', '.join(request.interest_tags)}
- ê¸°ê°„: {request.study_project_start} ~ {request.study_project_end}

**ìš”êµ¬ì‚¬í•­:**
1. {request.type_check} ê¸°ê°„ì— ë§ëŠ” ì£¼ì°¨ë³„ ì»¤ë¦¬í˜ëŸ¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”
2. ê° ì£¼ì°¨ë³„ë¡œ í•™ìŠµ ëª©í‘œ, ì£¼ìš” ë‚´ìš©, ì‹¤ìŠµ ê³¼ì œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”
3. {', '.join(request.interest_tags)} ë¶„ì•¼ì˜ í•µì‹¬ ê°œë…ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•´ì£¼ì„¸ìš”
4. ë ˆë²¨ {request.study_level}ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”
5. ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ ì‹¤ìŠµê³¼ í”„ë¡œì íŠ¸ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”

**ì¶œë ¥ í˜•ì‹:**
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ì£¼ì°¨ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„
- ê° ì£¼ì°¨ë§ˆë‹¤ í•™ìŠµ ëª©í‘œ, ì£¼ìš” ë‚´ìš©, ì‹¤ìŠµ ê³¼ì œ í¬í•¨
- ë§ˆì§€ë§‰ì— ì „ì²´ í•™ìŠµ ì„±ê³¼ í‰ê°€ ë°©ë²• ì œì‹œ

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        # OpenAI GPT API í˜¸ì¶œ
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì´ì ì»¤ë¦¬í˜ëŸ¼ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ì¸ í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ì„ ì„¤ê³„í•˜ëŠ” ê²ƒì´ íŠ¹ê¸°ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.7
        )
        
        # ì‘ë‹µì—ì„œ ì»¤ë¦¬í˜ëŸ¼ ì¶”ì¶œ
        curriculum = response.choices[0].message.content.strip()
        
        # ë””ë²„ê¹…: ìƒì„±ëœ ì»¤ë¦¬í˜ëŸ¼ ì¶œë ¥
        print(f"Generated Curriculum (UTF-8): {curriculum}")
        print(f"Curriculum length: {len(curriculum)}")
        print(f"Curriculum encoding check: {curriculum.encode('utf-8')}")
        
        return CurriculumResponse(
            study_project_id=request.study_project_id,
            curriculum=curriculum,
            message="ì»¤ë¦¬í˜ëŸ¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            success=True,
            generated_at=datetime.now().isoformat()
        )
        
    except Exception as e:
        print(f"Error in generate_curriculum: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì»¤ë¦¬í˜ëŸ¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/generate-feedback", response_model=FeedbackResponse)
async def generate_feedback(request: FeedbackRequest):
    """
    OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ì œ ì œì¶œì— ëŒ€í•œ ìƒì„¸í•œ í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        # OpenAI API í‚¤ í™•ì¸
        if not openai.api_key:
            raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì œì¶œ ë‚´ìš©ì´ ì½”ë“œì¸ì§€ íŒë‹¨
        is_code_submission = detect_code_submission(request.submission_content)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ì½”ë“œì¸ ê²½ìš° ì½”ë“œ ë¦¬ë·° í˜•ì‹, ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ì¼ë°˜ í”¼ë“œë°± í˜•ì‹
        if is_code_submission:
            prompt = f"""
ë‹¤ìŒ ê³¼ì œ ì œì¶œì— ëŒ€í•œ ì „ë¬¸ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.

**ê³¼ì œ ì •ë³´:**
- ì œëª©: {request.assignment_title}
- ì„¤ëª…: {request.assignment_description}

**ì œì¶œëœ ì½”ë“œ:**
```code
{request.submission_content}
```

**ì²¨ë¶€ íŒŒì¼:** {request.submission_file_url if request.submission_file_url else 'ì—†ìŒ'}

**ì½”ë“œ ë¦¬ë·° ê¸°ì¤€ ë° ìš”êµ¬ì‚¬í•­:**

**1. ì½”ë“œ í’ˆì§ˆ (0-10ì )**
- ì½”ë“œ êµ¬ì¡°ì™€ ì•„í‚¤í…ì²˜
- í•¨ìˆ˜/í´ë˜ìŠ¤ ì„¤ê³„ì˜ ì ì ˆì„±
- ë³€ìˆ˜ëª…ê³¼ í•¨ìˆ˜ëª…ì˜ ëª…í™•ì„±
- ì½”ë“œ ë³µì¡ë„ì™€ ê°€ë…ì„±

**2. ê¸°ëŠ¥ êµ¬í˜„ (0-10ì )**
- ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„
- í•µì‹¬ ê¸°ëŠ¥ì˜ ì •í™•í•œ êµ¬í˜„
- ì˜ˆì™¸ ì²˜ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§
- ì…ë ¥ ê²€ì¦ ë° ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

**3. ì„±ëŠ¥ ë° ìµœì í™” (0-10ì )**
- ì•Œê³ ë¦¬ì¦˜ íš¨ìœ¨ì„±
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- ì‹œê°„ ë³µì¡ë„
- ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

**4. ì½”ë“œ ìŠ¤íƒ€ì¼ ë° ì»¨ë²¤ì…˜ (0-10ì )**
- ì½”ë”© ìŠ¤íƒ€ì¼ ì¼ê´€ì„±
- ë“¤ì—¬ì“°ê¸° ë° í¬ë§·íŒ…
- ì£¼ì„ ë° ë¬¸ì„œí™”
- ë„¤ì´ë° ì»¨ë²¤ì…˜ ì¤€ìˆ˜

**5. í…ŒìŠ¤íŠ¸ ë° ìœ ì§€ë³´ìˆ˜ì„± (0-10ì )**
- í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±
- ì½”ë“œ ì¬ì‚¬ìš©ì„±
- í™•ì¥ì„± ë° ìœ ì—°ì„±
- ë””ë²„ê¹… ìš©ì´ì„±

**6. ë³´ì•ˆ ë° ëª¨ë²” ì‚¬ë¡€ (0-10ì )**
- ë³´ì•ˆ ì·¨ì•½ì 
- ì…ë ¥ ê²€ì¦
- ì—ëŸ¬ ë©”ì‹œì§€ ë…¸ì¶œ
- ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

**ìš”êµ¬ì‚¬í•­:**
- ìµœì¢… ì ìˆ˜ëŠ” -5ì ì—ì„œ 10ì  ì‚¬ì´ë¡œ ì„¤ì •
- ê° í‰ê°€ ê¸°ì¤€ë³„ë¡œ êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œì™€ ê·¼ê±° ì œì‹œ
- ì½”ë“œì˜ ì¥ì ê³¼ ê°œì„ ì ì„ ëª…í™•í•˜ê²Œ ë¶„ì„
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë¦¬íŒ©í† ë§ ì œì•ˆ
- ë³´ì•ˆ ì·¨ì•½ì ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ ì œì‹œ
- ê±´ì„¤ì ì´ê³  ê²©ë ¤ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±
- í•œêµ­ì–´ë¡œ ì‘ì„±

**ì¶œë ¥ í˜•ì‹:**
ì ìˆ˜: [ìµœì¢…ì ìˆ˜]
ì½”ë©˜íŠ¸: [ê°„ë‹¨í•œ ìš”ì•½ - í•µì‹¬ í‰ê°€ ê²°ê³¼ì™€ ì „ë°˜ì ì¸ ì¸ìƒ]
ìƒì„¸ í”¼ë“œë°±: [êµ¬ì²´ì ì¸ ì½”ë“œ ë¦¬ë·° - ê° í‰ê°€ ê¸°ì¤€ë³„ ìƒì„¸ ë¶„ì„, ì½”ë“œ ì˜ˆì‹œ, ë¦¬íŒ©í† ë§ ì œì•ˆ, ë³´ì•ˆ ê°œì„  ë°©ì•ˆ, í•™ìŠµ ë°©í–¥ ì œì‹œ]
"""
        else:
            prompt = f"""
ë‹¤ìŒ ê³¼ì œ ì œì¶œì— ëŒ€í•œ ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ê³¼ì œ ì •ë³´:**
- ì œëª©: {request.assignment_title}
- ì„¤ëª…: {request.assignment_description}

**ì œì¶œ ë‚´ìš©:**
{request.submission_content}

**ì²¨ë¶€ íŒŒì¼:** {request.submission_file_url if request.submission_file_url else 'ì—†ìŒ'}

**í‰ê°€ ê¸°ì¤€ ë° ìš”êµ¬ì‚¬í•­:**

**1. ë‚´ìš©ì˜ ì™„ì„±ë„ (0-10ì )**
- ê³¼ì œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„
- í•µì‹¬ ê°œë… ì´í•´ë„
- êµ¬í˜„ ì™„ì„±ë„

**2. ë…¼ë¦¬ì  êµ¬ì¡° (0-10ì )**
- ë‚´ìš©ì˜ ë…¼ë¦¬ì  íë¦„
- êµ¬ì¡°ì  ì„¤ê³„ì˜ ì ì ˆì„±
- ë‹¨ê³„ë³„ ì ‘ê·¼ì˜ ëª…í™•ì„±

**3. ê¸°ìˆ ì  ì •í™•ì„± (0-10ì )**
- ê¸°ìˆ ì  êµ¬í˜„ì˜ ì •í™•ì„±
- ì—ëŸ¬ë‚˜ ë²„ê·¸ì˜ ì¡´ì¬ ì—¬ë¶€
- ìµœì í™” ìˆ˜ì¤€

**4. ê°œì„  ê°€ëŠ¥ì„± (0-10ì )**
- í–¥í›„ ë°œì „ ë°©í–¥
- ì¶”ê°€ í•™ìŠµì´ í•„ìš”í•œ ë¶€ë¶„
- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±

**ìš”êµ¬ì‚¬í•­:**
- ìµœì¢… ì ìˆ˜ëŠ” -5ì ì—ì„œ 10ì  ì‚¬ì´ë¡œ ì„¤ì •
- ê° í‰ê°€ ê¸°ì¤€ë³„ë¡œ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±° ì œì‹œ
- ì œì¶œ ë‚´ìš©ì˜ ì¥ì ê³¼ ë‹¨ì ì„ ëª…í™•í•˜ê²Œ ë¶„ì„
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ ì œì‹œ
- ê±´ì„¤ì ì´ê³  ê²©ë ¤ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±
- í•œêµ­ì–´ë¡œ ì‘ì„±

**ì¶œë ¥ í˜•ì‹:**
ì ìˆ˜: [ìµœì¢…ì ìˆ˜]
ì½”ë©˜íŠ¸: [ê°„ë‹¨í•œ ìš”ì•½ - í•µì‹¬ í‰ê°€ ê²°ê³¼ì™€ ì „ë°˜ì ì¸ ì¸ìƒ]
ìƒì„¸ í”¼ë“œë°±: [êµ¬ì²´ì ì¸ ë¶„ì„ê³¼ ê°œì„  ë°©ì•ˆ - ê° í‰ê°€ ê¸°ì¤€ë³„ ìƒì„¸ ë¶„ì„, êµ¬ì²´ì ì¸ ì˜ˆì‹œ, ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì œì•ˆ, í•™ìŠµ ë°©í–¥ ì œì‹œ]
"""
        
        # OpenAI GPT API í˜¸ì¶œ
        if is_code_submission:
            system_message = "ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ê°œë°œìì´ì ì½”ë“œ ë¦¬ë·° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ì œê³µí•˜ë©°, ê°œë°œìì˜ ì„±ì¥ì„ ë•ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ê° í‰ê°€ ê¸°ì¤€ë³„ë¡œ êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì‹œì™€ ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ë¦¬íŒ©í† ë§ ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤."
        else:
            system_message = "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì´ì ê³¼ì œ í‰ê°€ìì…ë‹ˆë‹¤. ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ë©°, í•™ìƒì˜ ì„±ì¥ì„ ë•ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ê° í‰ê°€ ê¸°ì¤€ë³„ë¡œ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤."
        
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            max_tokens=2500,  # ì½”ë“œ ë¦¬ë·°ì˜ ê²½ìš° ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
            temperature=0.7   # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
        )
        
        # ì‘ë‹µì—ì„œ í”¼ë“œë°± ì¶”ì¶œ
        feedback_text = response.choices[0].message.content.strip()
        
        # ì ìˆ˜ì™€ ì½”ë©˜íŠ¸ ì¶”ì¶œ
        lines = feedback_text.split('\n')
        score = 0
        comment = ""
        detailed_feedback = ""
        
        for line in lines:
            if line.startswith('ì ìˆ˜:'):
                try:
                    score_text = line.replace('ì ìˆ˜:', '').strip()
                    score = int(score_text)
                    # ì ìˆ˜ ë²”ìœ„ ì œí•œ (-5 ~ 10)
                    score = max(-5, min(10, score))
                except ValueError:
                    score = 5  # ê¸°ë³¸ê°’
            elif line.startswith('ì½”ë©˜íŠ¸:'):
                comment = line.replace('ì½”ë©˜íŠ¸:', '').strip()
            elif line.startswith('ìƒì„¸ í”¼ë“œë°±:'):
                detailed_feedback = line.replace('ìƒì„¸ í”¼ë“œë°±:', '').strip()
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not comment:
            if is_code_submission:
                comment = "ì½”ë“œ ë¦¬ë·°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                comment = "ê³¼ì œ ì œì¶œì— ëŒ€í•œ ìƒì„¸í•œ í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        if not detailed_feedback:
            detailed_feedback = feedback_text
        
        # ì½”ë©˜íŠ¸ì™€ ìƒì„¸ í”¼ë“œë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
        integrated_comment = create_integrated_comment(comment, detailed_feedback, is_code_submission)
        
        return FeedbackResponse(
            score=score,
            comment=integrated_comment,  # í†µí•©ëœ ì½”ë©˜íŠ¸ ë°˜í™˜
            detailed_feedback=detailed_feedback
        )
        
    except Exception as e:
        print(f"Error in generate_feedback: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def detect_code_submission(content):
    """
    ì œì¶œ ë‚´ìš©ì´ ì½”ë“œì¸ì§€ íŒë‹¨
    """
    if not content:
        return False
    
    # ì½”ë“œë¡œ íŒë‹¨í•  ìˆ˜ ìˆëŠ” í‚¤ì›Œë“œë“¤
    code_keywords = [
        'public', 'private', 'class', 'function', 'def', 'var', 'let', 'const',
        'if', 'else', 'for', 'while', 'return', 'import', 'package', 'namespace',
        'try', 'catch', 'throw', 'new', 'this', 'super', 'extends', 'implements',
        'int', 'String', 'boolean', 'void', 'null', 'true', 'false',
        'console.log', 'System.out.println', 'print', 'printf',
        '=>', '->', '::', '++', '--', '&&', '||', '!', '==', '===', '!=', '!=='
    ]
    
    # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ í™•ì¸
    if '```' in content or '`' in content:
        return True
    
    # ì½”ë“œ í‚¤ì›Œë“œ í™•ì¸
    content_lower = content.lower()
    keyword_count = sum(1 for keyword in code_keywords if keyword.lower() in content_lower)
    
    # í‚¤ì›Œë“œê°€ 3ê°œ ì´ìƒ ìˆìœ¼ë©´ ì½”ë“œë¡œ íŒë‹¨
    return keyword_count >= 3

def create_integrated_comment(comment, detailed_feedback, is_code_submission=False):
    """
    ì½”ë©˜íŠ¸ì™€ ìƒì„¸ í”¼ë“œë°±ì„ í•˜ë‚˜ë¡œ í†µí•©
    """
    integrated = []
    
    # 1. ê°„ë‹¨í•œ ìš”ì•½ (ì½”ë©˜íŠ¸)
    if comment and comment.strip():
        if is_code_submission:
            integrated.append("ğŸ” **ì½”ë“œ ë¦¬ë·° ìš”ì•½:**")
        else:
            integrated.append("ğŸ“ **ê°„ë‹¨í•œ ìš”ì•½:**")
        integrated.append(comment.strip())
        integrated.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # 2. ìƒì„¸ í”¼ë“œë°±
    if detailed_feedback and detailed_feedback.strip():
        if is_code_submission:
            integrated.append("ğŸ’» **ìƒì„¸ ì½”ë“œ ë¦¬ë·°:**")
        else:
            integrated.append("ğŸ” **ìƒì„¸ í”¼ë“œë°±:**")
        integrated.append(detailed_feedback.strip())
    
    return "\n".join(integrated)

@app.get("/models")
async def get_available_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ OpenAI ëª¨ë¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        models = openai.Model.list()
        return {"models": [model.id for model in models.data]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if __name__ == "__main__":
    print("Starting FastAPI server with UTF-8 encoding...")
    print(f"System encoding: {sys.getdefaultencoding()}")
    print(f"Stdout encoding: {sys.stdout.encoding}")
    
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
